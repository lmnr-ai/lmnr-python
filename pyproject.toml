# Laminar Python

# If you are looking for information about possible extras installations,
# i.e. what you can pass into `pip install 'lmnr[extra1,extra2]'`, please see the
# `[project.optional-dependencies]` section below.

[project]
name = "lmnr"
version = "0.6.6"
description = "Python SDK for Laminar"
authors = [
  { name = "lmnr.ai", email = "founders@lmnr.ai" }
]
readme = "README.md"
requires-python = ">=3.10,<4"
license = "Apache-2.0"
dependencies = [
  "pydantic (>=2.0.3,<3.0.0)",
  "python-dotenv (>=1.0)",
  "opentelemetry-api (>=1.33.0)",
  "opentelemetry-sdk (>=1.33.0)",
  "opentelemetry-exporter-otlp-proto-http (>=1.33.0)",
  "opentelemetry-exporter-otlp-proto-grpc (>=1.33.0)",
  "opentelemetry-semantic-conventions (>=0.54b0)",
  "opentelemetry-semantic-conventions-ai (>=0.4.8)",
  "tqdm (>=4.0)",
  "argparse (>=1.0)",
  "tenacity (>=8.0)",
  # explicitly freeze grpcio. Since 1.68.0, grpcio writes a warning message
  # that looks scary, but is harmless.
  # WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
  # E0000 00:00:1737439981.199902 9456033 init.cc:229] grpc_wait_for_shutdown_with_timeout() timed out.
  #
  # Related issue:
  # https://discuss.ai.google.dev/t/warning-all-log-messages-before-absl-initializelog-is-called-are-written-to-stderr-e0000-001731955515-629532-17124-init-cc-229-grpc-wait-for-shutdown-with-timeout-timed-out/50020
  # https://github.com/grpc/grpc/issues/38490
  "grpcio<1.68.0",
  "httpx>=0.25.0",
  "opentelemetry-instrumentation-threading>=0.54b0",
]

[project.scripts]
lmnr = "lmnr.cli:cli"

[project.optional-dependencies]
# List of all possible extras. You can specify one or more of these extras
# when installing the package, using any of the following examples:
# `pip install 'lmnr[anthropic,openai]'`
# `uv pip install 'lmnr[anthropic,openai]'`
# `uv add lmnr --extra anthropic --extra openai`
# `poetry add 'lmnr[anthropic,openai]'`

alephalpha=["opentelemetry-instrumentation-alephalpha>=0.40.5"]
anthropic=["opentelemetry-instrumentation-anthropic>=0.40.5"]
bedrock=["opentelemetry-instrumentation-bedrock>=0.40.5"]
chromadb=["opentelemetry-instrumentation-chromadb>=0.40.5"]
cohere=["opentelemetry-instrumentation-cohere>=0.40.5"]
crewai=["opentelemetry-instrumentation-crewai>=0.40.5"]
google-generativeai=["opentelemetry-instrumentation-google-generativeai>=0.40.5"]
groq=["opentelemetry-instrumentation-groq>=0.40.5"]
haystack=["opentelemetry-instrumentation-haystack>=0.40.5"]
lancedb=["opentelemetry-instrumentation-lancedb>=0.40.5"]
langchain=["opentelemetry-instrumentation-langchain>=0.40.5"]
llamaindex=["opentelemetry-instrumentation-llamaindex>=0.40.5"]
marqo=["opentelemetry-instrumentation-marqo>=0.40.5"]
mcp=["opentelemetry-instrumentation-mcp>=0.40.5"]
milvus=["opentelemetry-instrumentation-milvus>=0.40.5"]
mistralai=["opentelemetry-instrumentation-mistralai>=0.40.5"]
ollama=["opentelemetry-instrumentation-ollama>=0.40.5"]
openai=["opentelemetry-instrumentation-openai>=0.40.5"]
pinecone=["opentelemetry-instrumentation-pinecone>=0.40.5"]
qdrant=["opentelemetry-instrumentation-qdrant>=0.40.5"]
replicate=["opentelemetry-instrumentation-replicate>=0.40.5"]
sagemaker=["opentelemetry-instrumentation-sagemaker>=0.40.5"]
together=["opentelemetry-instrumentation-together>=0.40.5"]
transformers=["opentelemetry-instrumentation-transformers>=0.40.5"]
vertexai=["opentelemetry-instrumentation-vertexai>=0.40.5"]
watsonx=["opentelemetry-instrumentation-watsonx>=0.40.5"]
weaviate=["opentelemetry-instrumentation-weaviate>=0.40.5"]
# `all` is the group added for convenience, if you want to install all
# the instrumentations.
# we suggest using package-manager-specific commands instead,
# like `uv add lmnr --all-extras`
all = [
  "opentelemetry-instrumentation-alephalpha>=0.40.5",
  "opentelemetry-instrumentation-anthropic>=0.40.5",
  "opentelemetry-instrumentation-bedrock>=0.40.5",
  "opentelemetry-instrumentation-chromadb>=0.40.5",
  "opentelemetry-instrumentation-cohere>=0.40.5",
  "opentelemetry-instrumentation-crewai>=0.40.5",
  "opentelemetry-instrumentation-google-generativeai>=0.40.5",
  "opentelemetry-instrumentation-groq>=0.40.5",
  "opentelemetry-instrumentation-haystack>=0.40.5",
  "opentelemetry-instrumentation-lancedb>=0.40.5",
  "opentelemetry-instrumentation-langchain>=0.40.5",
  "opentelemetry-instrumentation-llamaindex>=0.40.5",
  "opentelemetry-instrumentation-marqo>=0.40.5",
  "opentelemetry-instrumentation-mcp>=0.40.5",
  "opentelemetry-instrumentation-milvus>=0.40.5",
  "opentelemetry-instrumentation-mistralai>=0.40.5",
  "opentelemetry-instrumentation-ollama>=0.40.5",
  "opentelemetry-instrumentation-openai>=0.40.5",
  "opentelemetry-instrumentation-pinecone>=0.40.5",
  "opentelemetry-instrumentation-qdrant>=0.40.5",
  "opentelemetry-instrumentation-replicate>=0.40.5",
  "opentelemetry-instrumentation-sagemaker>=0.40.5",
  "opentelemetry-instrumentation-together>=0.40.5",
  "opentelemetry-instrumentation-transformers>=0.40.5",
  "opentelemetry-instrumentation-vertexai>=0.40.5",
  "opentelemetry-instrumentation-watsonx>=0.40.5",
  "opentelemetry-instrumentation-weaviate>=0.40.5"
]

[dependency-groups]
dev = [
  "autopep8>=2.3.2",
  "flake8>=7.2.0",
  "pytest>=8.3.5",
  "pytest-sugar>=1.0.0",
  "pytest-asyncio>=0.26.0",
  "playwright>=1.52.0",
  "vcrpy>=7.0.0",
  "openai>=1.77.0",
  "pytest-recording>=0.13.4",
  "patchright>=1.52.3",
]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.uv.workspace]
members = ["examples/fastapi-app"]
# we can move to uv_build, once it's more stable
# https://github.com/astral-sh/uv/issues/3957
# requires = ["uv_build>=0.6.16,<0.7"]
# build-backend = "uv_build"
